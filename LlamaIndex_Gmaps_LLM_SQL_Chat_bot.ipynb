{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from llama_index.core import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"timelineObjects\": [\n",
      "        {\n",
      "            \"activitySegment\": {\n",
      "                \"startLocation\": {\n",
      "                    \"latitudeE7\": 329932296,\n",
      "                    \"longitudeE7\": -967526711,\n",
      "                    \"sourceInfo\": {\n",
      "                        \"deviceTag\": -1349438752\n",
      "                    }\n",
      "                },\n",
      "                \"endLocation\": {\n",
      "                    \"latitudeE7\": 329980399,\n",
      "                    \"longitudeE7\": -967689368,\n",
      "                    \"sourceInfo\": {\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to the file\n",
    "file_path = r'C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_APRIL.json'\n",
    "\n",
    "# Open and load the JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print a sample of the data to verify\n",
    "print(json.dumps(data, indent=4)[:500])  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_APRIL.json\n",
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_AUGUST.json\n",
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_DECEMBER.json\n",
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_FEBRUARY.json\n",
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_JANUARY.json\n",
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_JULY.json\n",
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_JUNE.json\n",
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_MARCH.json\n",
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_MAY.json\n",
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_NOVEMBER.json\n",
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_OCTOBER.json\n",
      "C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023\\2023_SEPTEMBER.json\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk(r'C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 12 files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for dirname, _, filenames in os.walk(r'C:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\Takeout\\Location History (Timeline)\\Semantic Location History\\2023'):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.json'):  # Ensure it's a JSON file\n",
    "            file_path = os.path.join(dirname, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                data_list.append(data)\n",
    "\n",
    "# Print the total number of files processed\n",
    "print(f\"Processed {len(data_list)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place Visits Table:\n",
      "\n",
      "Activity Segments Table:\n"
     ]
    }
   ],
   "source": [
    "# Lists to store extracted data\n",
    "place_visits = []\n",
    "activity_segments = []\n",
    "\n",
    "# Iterate through the data_list (assuming data_list contains the raw data in the required format)\n",
    "for i in range(12):\n",
    "    for entry in data_list[i].get('timelineObjects', []):\n",
    "        if 'placeVisit' in entry:\n",
    "            place_visit = entry['placeVisit']\n",
    "            place_visits.append({\n",
    "                'latitude': place_visit['location'].get('latitudeE7', None) / 1e7,\n",
    "                'longitude': place_visit['location'].get('longitudeE7', None) / 1e7,\n",
    "                'place_id': place_visit['location'].get('placeId', None),\n",
    "                'address': place_visit['location'].get('address', None),\n",
    "                'start_timestamp': place_visit['duration'].get('startTimestamp', None),\n",
    "                'end_timestamp': place_visit['duration'].get('endTimestamp', None),\n",
    "                'location_confidence': place_visit.get('locationConfidence', None),\n",
    "                'visit_confidence': place_visit.get('visitConfidence', None),\n",
    "            })\n",
    "        \n",
    "        if 'activitySegment' in entry:\n",
    "            activity_segment = entry['activitySegment']\n",
    "            activity_segments.append({\n",
    "                'start_latitude': activity_segment['startLocation'].get('latitudeE7', None) / 1e7,\n",
    "                'start_longitude': activity_segment['startLocation'].get('longitudeE7', None) / 1e7,\n",
    "                'end_latitude': activity_segment['endLocation'].get('latitudeE7', None) / 1e7,\n",
    "                'end_longitude': activity_segment['endLocation'].get('longitudeE7', None) / 1e7,\n",
    "                'start_timestamp': activity_segment['duration'].get('startTimestamp', None),\n",
    "                'end_timestamp': activity_segment['duration'].get('endTimestamp', None),\n",
    "                'distance': activity_segment.get('distance', None),\n",
    "                'activity_type': activity_segment.get('activityType', None),\n",
    "                'confidence': activity_segment.get('confidence', None),\n",
    "            })\n",
    "\n",
    "# Convert the lists to DataFrames\n",
    "place_visits_df = pd.DataFrame(place_visits)\n",
    "activity_segments_df = pd.DataFrame(activity_segments)\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Place Visits Table:\")\n",
    "#print(place_visits_df)\n",
    "\n",
    "print(\"\\nActivity Segments Table:\")\n",
    "#print(activity_segments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place Visits:\n",
      "      latitude  longitude                     place_id  \\\n",
      "0    32.998563 -96.769852  ChIJlUIIxBciTIYRJ1BkpUz-9QA   \n",
      "1    33.004202 -96.771651  ChIJsXzjiRUiTIYRFWVIzCBQ1Bc   \n",
      "2    32.998563 -96.769852  ChIJlUIIxBciTIYRJ1BkpUz-9QA   \n",
      "3    32.985697 -96.750247  ChIJpUpeif8hTIYRMROq6TKLCdk   \n",
      "4    32.998563 -96.769852  ChIJlUIIxBciTIYRJ1BkpUz-9QA   \n",
      "..         ...        ...                          ...   \n",
      "910  32.993592 -96.750252  ChIJxblxuDSgToYRcn4cxwiPeVU   \n",
      "911  32.985697 -96.750247  ChIJpUpeif8hTIYRMROq6TKLCdk   \n",
      "912  32.998563 -96.769852  ChIJlUIIxBciTIYRJ1BkpUz-9QA   \n",
      "913  33.004202 -96.771651  ChIJsXzjiRUiTIYRFWVIzCBQ1Bc   \n",
      "914  32.998563 -96.769852  ChIJlUIIxBciTIYRJ1BkpUz-9QA   \n",
      "\n",
      "                                            address           start_timestamp  \\\n",
      "0          7575 Frankford Rd, Dallas, TX 75252, USA  2023-04-01T01:04:38.927Z   \n",
      "1                 425 Coit Rd, Plano, TX 75075, USA  2023-04-01T02:41:01.332Z   \n",
      "2          7575 Frankford Rd, Dallas, TX 75252, USA  2023-04-01T03:20:53.553Z   \n",
      "3      800 W Campbell Rd, Richardson, TX 75080, USA  2023-04-01T18:26:08.835Z   \n",
      "4          7575 Frankford Rd, Dallas, TX 75252, USA  2023-04-02T01:24:41.611Z   \n",
      "..                                              ...                       ...   \n",
      "910  3000 Northside Blvd, Richardson, TX 75080, USA  2023-09-30T18:40:48.032Z   \n",
      "911    800 W Campbell Rd, Richardson, TX 75080, USA  2023-09-30T19:12:05.585Z   \n",
      "912        7575 Frankford Rd, Dallas, TX 75252, USA  2023-09-30T20:17:07.756Z   \n",
      "913               425 Coit Rd, Plano, TX 75075, USA  2023-09-30T21:56:39.524Z   \n",
      "914        7575 Frankford Rd, Dallas, TX 75252, USA  2023-09-30T22:16:38.278Z   \n",
      "\n",
      "                end_timestamp  location_confidence  visit_confidence  \n",
      "0    2023-04-01T02:34:07.602Z                   48                84  \n",
      "1    2023-04-01T03:16:14.978Z                   83                92  \n",
      "2    2023-04-01T18:01:45.261Z                   45                96  \n",
      "3    2023-04-02T00:57:32.157Z                   57                96  \n",
      "4    2023-04-02T10:36:43.460Z                   43                96  \n",
      "..                        ...                  ...               ...  \n",
      "910  2023-09-30T19:02:55.164Z                   42                92  \n",
      "911  2023-09-30T20:01:49.834Z                   63                77  \n",
      "912  2023-09-30T21:53:37.869Z                   68                78  \n",
      "913  2023-09-30T22:13:12.006Z                   82                91  \n",
      "914  2023-10-01T15:05:52.974Z                   70                91  \n",
      "\n",
      "[915 rows x 8 columns]\n",
      "\n",
      "Activity Segments:\n",
      "      start_latitude  start_longitude  end_latitude  end_longitude  \\\n",
      "0          32.993230       -96.752671     32.998040     -96.768937   \n",
      "1          32.998462       -96.769793     33.003861     -96.770421   \n",
      "2          33.003794       -96.771146     32.998320     -96.769430   \n",
      "3          32.997971       -96.768856     32.987089     -96.748480   \n",
      "4          32.984000       -96.749578     32.998376     -96.770021   \n",
      "...              ...              ...           ...            ...   \n",
      "1010       32.985014       -96.747746     32.993521     -96.750719   \n",
      "1011       32.993517       -96.750632     32.986913     -96.750220   \n",
      "1012       32.985998       -96.748669     32.999101     -96.770573   \n",
      "1013       32.997929       -96.769560     33.004590     -96.771091   \n",
      "1014       33.004538       -96.771097     32.999008     -96.769773   \n",
      "\n",
      "               start_timestamp             end_timestamp  distance  \\\n",
      "0     2023-04-01T00:58:54.904Z  2023-04-01T01:04:38.927Z    1869.0   \n",
      "1     2023-04-01T02:34:07.602Z  2023-04-01T02:41:01.332Z    1345.0   \n",
      "2     2023-04-01T03:16:14.978Z  2023-04-01T03:20:53.553Z     761.0   \n",
      "3     2023-04-01T18:01:45.261Z  2023-04-01T18:26:08.835Z    4779.0   \n",
      "4     2023-04-02T00:57:32.157Z  2023-04-02T01:24:41.611Z    5383.0   \n",
      "...                        ...                       ...       ...   \n",
      "1010  2023-09-30T18:25:47.474Z  2023-09-30T18:40:48.032Z    1103.0   \n",
      "1011  2023-09-30T19:02:55.164Z  2023-09-30T19:12:05.585Z     749.0   \n",
      "1012  2023-09-30T20:01:49.834Z  2023-09-30T20:17:07.756Z    5111.0   \n",
      "1013  2023-09-30T21:53:37.869Z  2023-09-30T21:56:39.524Z     947.0   \n",
      "1014  2023-09-30T22:13:12.006Z  2023-09-30T22:16:38.278Z     627.0   \n",
      "\n",
      "             activity_type confidence  \n",
      "0                   IN_BUS     MEDIUM  \n",
      "1     IN_PASSENGER_VEHICLE       HIGH  \n",
      "2     IN_PASSENGER_VEHICLE     MEDIUM  \n",
      "3                  CYCLING        LOW  \n",
      "4                   IN_BUS        LOW  \n",
      "...                    ...        ...  \n",
      "1010               WALKING       HIGH  \n",
      "1011               WALKING       HIGH  \n",
      "1012  IN_PASSENGER_VEHICLE        LOW  \n",
      "1013  IN_PASSENGER_VEHICLE       HIGH  \n",
      "1014  IN_PASSENGER_VEHICLE       HIGH  \n",
      "\n",
      "[1015 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print DataFrames\n",
    "print(\"Place Visits:\")\n",
    "print(place_visits_df)\n",
    "print(\"\\nActivity Segments:\")\n",
    "print(activity_segments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_place_visits(timeline_objects):\n",
    "    \"\"\"\n",
    "    Extract place visits from timeline objects and return a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    timeline_objects (list): List of timeline objects containing place visits.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with place visit details.\n",
    "    \"\"\"\n",
    "    place_visits = []\n",
    "    for entry in timeline_objects:\n",
    "        if 'placeVisit' in entry:\n",
    "            place_visit = entry['placeVisit']\n",
    "            # Extracting data\n",
    "            visit_data = {\n",
    "                'latitude': place_visit['location'].get('latitudeE7', None) / 1e7,\n",
    "                'longitude': place_visit['location'].get('longitudeE7', None) / 1e7,\n",
    "                'place_id': place_visit['location'].get('placeId', None),\n",
    "                'address': place_visit['location'].get('address', None),\n",
    "                'start_timestamp': place_visit['duration'].get('startTimestamp', None),\n",
    "                'end_timestamp': place_visit['duration'].get('endTimestamp', None),\n",
    "                'location_confidence': place_visit.get('locationConfidence', None),\n",
    "                'visit_confidence': place_visit.get('visitConfidence', None),\n",
    "            }\n",
    "            \n",
    "            # Extract highest probability candidate from otherCandidateLocations\n",
    "            other_candidates = place_visit.get('otherCandidateLocations', [])\n",
    "            if other_candidates:\n",
    "                highest_prob_candidate = max(\n",
    "                    other_candidates, \n",
    "                    key=lambda x: x.get('calibratedProbability', 0)\n",
    "                )\n",
    "                visit_data['highest_prob_place_name'] = highest_prob_candidate.get('name', None)\n",
    "                visit_data['highest_prob_probability'] = highest_prob_candidate.get('calibratedProbability', None)\n",
    "            else:\n",
    "                visit_data['highest_prob_place_name'] = None\n",
    "                visit_data['highest_prob_probability'] = None\n",
    "            \n",
    "            place_visits.append(visit_data)\n",
    "    return pd.DataFrame(place_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activity_segments(timeline_objects):\n",
    "    \"\"\"\n",
    "    Extract activity segments from timeline objects and return a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    timeline_objects (list): List of timeline objects containing activity segments.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with activity segment details.\n",
    "    \"\"\"\n",
    "    activity_segments = []\n",
    "    for entry in timeline_objects:\n",
    "        if 'activitySegment' in entry:\n",
    "            activity_segment = entry['activitySegment']\n",
    "            activity_segments.append({\n",
    "                'start_latitude': activity_segment['startLocation'].get('latitudeE7', None) / 1e7,\n",
    "                'start_longitude': activity_segment['startLocation'].get('longitudeE7', None) / 1e7,\n",
    "                'end_latitude': activity_segment['endLocation'].get('latitudeE7', None) / 1e7,\n",
    "                'end_longitude': activity_segment['endLocation'].get('longitudeE7', None) / 1e7,\n",
    "                'start_timestamp': activity_segment['duration'].get('startTimestamp', None),\n",
    "                'end_timestamp': activity_segment['duration'].get('endTimestamp', None),\n",
    "                'distance': activity_segment.get('distance', None),\n",
    "                'activity_type': activity_segment.get('activityType', None),\n",
    "                'confidence': activity_segment.get('confidence', None),\n",
    "            })\n",
    "    return pd.DataFrame(activity_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_timeline_data(data_list):\n",
    "    \"\"\"\n",
    "    Process the entire dataset to extract place visits and activity segments.\n",
    "\n",
    "    Parameters:\n",
    "    data_list (list): List of raw data containing timeline objects.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Two DataFrames - place_visits_df and activity_segments_df.\n",
    "    \"\"\"\n",
    "    place_visits = []\n",
    "    activity_segments = []\n",
    "\n",
    "    # Iterate through data_list and process timeline objects\n",
    "    for i in range(len(data_list)):\n",
    "        timeline_objects = data_list[i].get('timelineObjects', [])\n",
    "        place_visits.append(extract_place_visits(timeline_objects))\n",
    "        activity_segments.append(extract_activity_segments(timeline_objects))\n",
    "\n",
    "    # Combine all results into DataFrames\n",
    "    place_visits_df = pd.concat(place_visits, ignore_index=True)\n",
    "    activity_segments_df = pd.concat(activity_segments, ignore_index=True)\n",
    "    \n",
    "    return place_visits_df, activity_segments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "place_visits_df, activity_segments_df = process_timeline_data(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_address_details(address):\n",
    "    try:\n",
    "        # Check if address is valid\n",
    "        if not address or pd.isna(address) or address == \"None\":\n",
    "            return pd.Series([\"Unknown\", \"Unknown\", \"Unknown\", \"Unknown\"])\n",
    "\n",
    "        # Split by comma\n",
    "        parts = address.split(\", \")\n",
    "        country = parts[-1] if len(parts) > 0 else \"Unknown\"\n",
    "        state_zip = parts[-2] if len(parts) > 1 else \"Unknown\"\n",
    "        city = parts[-3] if len(parts) > 2 else \"Unknown\"\n",
    "\n",
    "        # Parse state and zip code\n",
    "        if \" \" in state_zip:\n",
    "            state, zipcode = state_zip.rsplit(\" \", 1)\n",
    "        else:\n",
    "            state, zipcode = state_zip, \"Unknown\"\n",
    "\n",
    "        return pd.Series([city, state, zipcode, country])\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing address: {e}\")\n",
    "        return pd.Series([\"Unknown\", \"Unknown\", \"Unknown\", \"Unknown\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the DataFrame\n",
    "place_visits_df[[\"city\", \"state\", \"zipcode\", \"country\"]] = place_visits_df[\"address\"].apply(extract_address_details)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#print(place_visits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the last 4 columns of Place Visits Table:\n",
      "Column 'city': ['Dallas' 'Plano' 'Richardson' 'Frisco' 'Irving' 'Unknown' 'Chicago'\n",
      " 'New Delhi' 'Bengaluru' 'Chennai' 'Koyambedu' 'Austin' 'SeaTac'\n",
      " 'Bellevue' 'Redmond' 'Fall City' 'Snoqualmie' 'North Bend' 'Issaquah'\n",
      " 'Lake Stevens' 'Auburn' 'Seattle' 'Allen' 'McKinney']\n",
      "Column 'state': ['TX' 'Unknown' 'IL' 'Delhi' 'Karnataka' 'Tamil Nadu' 'Chennai' 'WA'\n",
      " 'Washington']\n",
      "Column 'zipcode': ['75252' '75075' '75080' '75035' '75039' '75034' '75024' '75248' 'Unknown'\n",
      " '75093' '75287' '75261' '60666' '110037' '534320' '560023' '600003'\n",
      " '600107' '600017' '600101' '600092' '600037' '600050' '600008' '600034'\n",
      " '75074' '75023' '75025' '75249' '75211' '75207' '75205' '75202' '75223'\n",
      " '78754' '78702' '78701' '78758' '78724' '78731' '75234' '98158' '98004'\n",
      " '98052' '98024' '98065' '98005' '98007' '98045' '98027' '98258' '98001'\n",
      " '98118' '98109' '98119' '98116' '75013' '75070' '75072' '75243' '75231'\n",
      " '75082']\n",
      "Column 'country': ['USA' 'Unknown' 'India' 'Tamil Nadu 600107']\n"
     ]
    }
   ],
   "source": [
    "# Display unique values for the last 4 columns\n",
    "print(\"Unique values in the last 4 columns of Place Visits Table:\")\n",
    "for col in place_visits_df.iloc[:, -4:].columns:\n",
    "    print(f\"Column '{col}': {place_visits_df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place Visits Table:\n",
      "130                       None\n",
      "222    Karnataka 534320, India\n",
      "326                       None\n",
      "336                       None\n",
      "656            Washington, USA\n",
      "Name: address, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Adjust display options for wide output\n",
    "pd.set_option('display.max_colwidth', None)  # Prevent truncation of column content\n",
    "pd.set_option('display.width', 0)  # Auto-adjust display width to prevent wrapping\n",
    "\n",
    "# Display results\n",
    "print(\"Place Visits Table:\")\n",
    "print(place_visits_df[place_visits_df['city'] == 'Unknown']['address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Activity Segments Table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_latitude</th>\n",
       "      <th>start_longitude</th>\n",
       "      <th>end_latitude</th>\n",
       "      <th>end_longitude</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>distance</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.993230</td>\n",
       "      <td>-96.752671</td>\n",
       "      <td>32.998040</td>\n",
       "      <td>-96.768937</td>\n",
       "      <td>2023-04-01T00:58:54.904Z</td>\n",
       "      <td>2023-04-01T01:04:38.927Z</td>\n",
       "      <td>1869.0</td>\n",
       "      <td>IN_BUS</td>\n",
       "      <td>MEDIUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.998462</td>\n",
       "      <td>-96.769793</td>\n",
       "      <td>33.003861</td>\n",
       "      <td>-96.770421</td>\n",
       "      <td>2023-04-01T02:34:07.602Z</td>\n",
       "      <td>2023-04-01T02:41:01.332Z</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>IN_PASSENGER_VEHICLE</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.003794</td>\n",
       "      <td>-96.771146</td>\n",
       "      <td>32.998320</td>\n",
       "      <td>-96.769430</td>\n",
       "      <td>2023-04-01T03:16:14.978Z</td>\n",
       "      <td>2023-04-01T03:20:53.553Z</td>\n",
       "      <td>761.0</td>\n",
       "      <td>IN_PASSENGER_VEHICLE</td>\n",
       "      <td>MEDIUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.997971</td>\n",
       "      <td>-96.768856</td>\n",
       "      <td>32.987089</td>\n",
       "      <td>-96.748480</td>\n",
       "      <td>2023-04-01T18:01:45.261Z</td>\n",
       "      <td>2023-04-01T18:26:08.835Z</td>\n",
       "      <td>4779.0</td>\n",
       "      <td>CYCLING</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.984000</td>\n",
       "      <td>-96.749578</td>\n",
       "      <td>32.998376</td>\n",
       "      <td>-96.770021</td>\n",
       "      <td>2023-04-02T00:57:32.157Z</td>\n",
       "      <td>2023-04-02T01:24:41.611Z</td>\n",
       "      <td>5383.0</td>\n",
       "      <td>IN_BUS</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_latitude  start_longitude  end_latitude  end_longitude  \\\n",
       "0       32.993230       -96.752671     32.998040     -96.768937   \n",
       "1       32.998462       -96.769793     33.003861     -96.770421   \n",
       "2       33.003794       -96.771146     32.998320     -96.769430   \n",
       "3       32.997971       -96.768856     32.987089     -96.748480   \n",
       "4       32.984000       -96.749578     32.998376     -96.770021   \n",
       "\n",
       "            start_timestamp             end_timestamp  distance  \\\n",
       "0  2023-04-01T00:58:54.904Z  2023-04-01T01:04:38.927Z    1869.0   \n",
       "1  2023-04-01T02:34:07.602Z  2023-04-01T02:41:01.332Z    1345.0   \n",
       "2  2023-04-01T03:16:14.978Z  2023-04-01T03:20:53.553Z     761.0   \n",
       "3  2023-04-01T18:01:45.261Z  2023-04-01T18:26:08.835Z    4779.0   \n",
       "4  2023-04-02T00:57:32.157Z  2023-04-02T01:24:41.611Z    5383.0   \n",
       "\n",
       "          activity_type confidence  \n",
       "0                IN_BUS     MEDIUM  \n",
       "1  IN_PASSENGER_VEHICLE       HIGH  \n",
       "2  IN_PASSENGER_VEHICLE     MEDIUM  \n",
       "3               CYCLING        LOW  \n",
       "4                IN_BUS        LOW  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nActivity Segments Table:\")\n",
    "activity_segments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>place_id</th>\n",
       "      <th>address</th>\n",
       "      <th>start_timestamp</th>\n",
       "      <th>end_timestamp</th>\n",
       "      <th>location_confidence</th>\n",
       "      <th>visit_confidence</th>\n",
       "      <th>highest_prob_place_name</th>\n",
       "      <th>highest_prob_probability</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>32.993592</td>\n",
       "      <td>-96.750252</td>\n",
       "      <td>ChIJxblxuDSgToYRcn4cxwiPeVU</td>\n",
       "      <td>3000 Northside Blvd, Richardson, TX 75080, USA</td>\n",
       "      <td>2023-09-30T18:40:48.032Z</td>\n",
       "      <td>2023-09-30T19:02:55.164Z</td>\n",
       "      <td>42</td>\n",
       "      <td>92</td>\n",
       "      <td>The University of Texas at Dallas</td>\n",
       "      <td>10.919032</td>\n",
       "      <td>Richardson</td>\n",
       "      <td>TX</td>\n",
       "      <td>75080</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>32.985697</td>\n",
       "      <td>-96.750247</td>\n",
       "      <td>ChIJpUpeif8hTIYRMROq6TKLCdk</td>\n",
       "      <td>800 W Campbell Rd, Richardson, TX 75080, USA</td>\n",
       "      <td>2023-09-30T19:12:05.585Z</td>\n",
       "      <td>2023-09-30T20:01:49.834Z</td>\n",
       "      <td>63</td>\n",
       "      <td>77</td>\n",
       "      <td>None</td>\n",
       "      <td>1.521476</td>\n",
       "      <td>Richardson</td>\n",
       "      <td>TX</td>\n",
       "      <td>75080</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>32.998563</td>\n",
       "      <td>-96.769852</td>\n",
       "      <td>ChIJlUIIxBciTIYRJ1BkpUz-9QA</td>\n",
       "      <td>7575 Frankford Rd, Dallas, TX 75252, USA</td>\n",
       "      <td>2023-09-30T20:17:07.756Z</td>\n",
       "      <td>2023-09-30T21:53:37.869Z</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>Estates on Frankford</td>\n",
       "      <td>7.957071</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>75252</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>33.004202</td>\n",
       "      <td>-96.771651</td>\n",
       "      <td>ChIJsXzjiRUiTIYRFWVIzCBQ1Bc</td>\n",
       "      <td>425 Coit Rd, Plano, TX 75075, USA</td>\n",
       "      <td>2023-09-30T21:56:39.524Z</td>\n",
       "      <td>2023-09-30T22:13:12.006Z</td>\n",
       "      <td>82</td>\n",
       "      <td>91</td>\n",
       "      <td>Sam's Club</td>\n",
       "      <td>0.711459</td>\n",
       "      <td>Plano</td>\n",
       "      <td>TX</td>\n",
       "      <td>75075</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>32.998563</td>\n",
       "      <td>-96.769852</td>\n",
       "      <td>ChIJlUIIxBciTIYRJ1BkpUz-9QA</td>\n",
       "      <td>7575 Frankford Rd, Dallas, TX 75252, USA</td>\n",
       "      <td>2023-09-30T22:16:38.278Z</td>\n",
       "      <td>2023-10-01T15:05:52.974Z</td>\n",
       "      <td>70</td>\n",
       "      <td>91</td>\n",
       "      <td>Estates on Frankford</td>\n",
       "      <td>8.427990</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>75252</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude  longitude                     place_id  \\\n",
       "910  32.993592 -96.750252  ChIJxblxuDSgToYRcn4cxwiPeVU   \n",
       "911  32.985697 -96.750247  ChIJpUpeif8hTIYRMROq6TKLCdk   \n",
       "912  32.998563 -96.769852  ChIJlUIIxBciTIYRJ1BkpUz-9QA   \n",
       "913  33.004202 -96.771651  ChIJsXzjiRUiTIYRFWVIzCBQ1Bc   \n",
       "914  32.998563 -96.769852  ChIJlUIIxBciTIYRJ1BkpUz-9QA   \n",
       "\n",
       "                                            address           start_timestamp  \\\n",
       "910  3000 Northside Blvd, Richardson, TX 75080, USA  2023-09-30T18:40:48.032Z   \n",
       "911    800 W Campbell Rd, Richardson, TX 75080, USA  2023-09-30T19:12:05.585Z   \n",
       "912        7575 Frankford Rd, Dallas, TX 75252, USA  2023-09-30T20:17:07.756Z   \n",
       "913               425 Coit Rd, Plano, TX 75075, USA  2023-09-30T21:56:39.524Z   \n",
       "914        7575 Frankford Rd, Dallas, TX 75252, USA  2023-09-30T22:16:38.278Z   \n",
       "\n",
       "                end_timestamp  location_confidence  visit_confidence  \\\n",
       "910  2023-09-30T19:02:55.164Z                   42                92   \n",
       "911  2023-09-30T20:01:49.834Z                   63                77   \n",
       "912  2023-09-30T21:53:37.869Z                   68                78   \n",
       "913  2023-09-30T22:13:12.006Z                   82                91   \n",
       "914  2023-10-01T15:05:52.974Z                   70                91   \n",
       "\n",
       "               highest_prob_place_name  highest_prob_probability        city  \\\n",
       "910  The University of Texas at Dallas                 10.919032  Richardson   \n",
       "911                               None                  1.521476  Richardson   \n",
       "912               Estates on Frankford                  7.957071      Dallas   \n",
       "913                         Sam's Club                  0.711459       Plano   \n",
       "914               Estates on Frankford                  8.427990      Dallas   \n",
       "\n",
       "    state zipcode country  \n",
       "910    TX   75080     USA  \n",
       "911    TX   75080     USA  \n",
       "912    TX   75252     USA  \n",
       "913    TX   75075     USA  \n",
       "914    TX   75252     USA  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_visits_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.vector_store import VectorStoreIndex\n",
    "from llama_index.core import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame rows to documents\n",
    "documents = []\n",
    "for _, row in place_visits_df.iterrows():\n",
    "    text = (\n",
    "        f\"Between {row['start_timestamp']} and {row['end_timestamp']}, you were at \"\n",
    "        f\"{row['highest_prob_place_name']} ({row['address']}), \"\n",
    "        f\"with a visit confidence of {row['visit_confidence']}% and \"\n",
    "        f\"location confidence of {row['location_confidence']}%.\\n\"\n",
    "        f\"Additional details: City - {row['city']}, State - {row['state']}, \"\n",
    "        f\"Zipcode - {row['zipcode']}, Country - {row['country']}.\"\n",
    "    )\n",
    "    documents.append(Document(text=text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Between 2023-04-01T02:41:01.332Z and 2023-04-01T03:16:14.978Z, you were at Mapleshade @ Coit - W - FS (425 Coit Rd, Plano, TX 75075, USA), with a visit confidence of 92% and location confidence of 83%.\\nAdditional details: City - Plano, State - TX, Zipcode - 75075, Country - USA.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from llama_index.core import VectorStoreIndex, Document\n",
    "\n",
    "# Initialize your embedding model (already done before)\n",
    "embed_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Create the index\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
    "\n",
    "# Optionally: Save the index to disk\n",
    "index.save_to_disk(\"place_visits_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import (\n",
    "    QueryPipeline as QP,\n",
    "    Link,\n",
    "    InputComponent,\n",
    ")\n",
    "from llama_index.experimental.query_engine.pandas import (\n",
    "    PandasInstructionParser,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_str = (\n",
    "    \"1. Convert the query to executable Python code using Pandas.\\n\"\n",
    "    \"2. The final line of code should be a Python expression that can be called with the `eval()` function.\\n\"\n",
    "    \"3. The code should represent a solution to the query.\\n\"\n",
    "    \"4. PRINT ONLY THE EXPRESSION.\\n\"\n",
    "    \"5. Do not quote the expression.\\n\"\n",
    ")\n",
    "\n",
    "pandas_prompt_str = (\n",
    "    \"You are working with a pandas dataframe in Python.\\n\"\n",
    "    \"The name of the dataframe is `df`.\\n\"\n",
    "    \"This is the result of `print(df.head())`:\\n\"\n",
    "    \"{df_str}\\n\\n\"\n",
    "    \"Follow these instructions:\\n\"\n",
    "    \"{instruction_str}\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Expression:\"\n",
    ")\n",
    "response_synthesis_prompt_str = (\n",
    "    \"Given an input question, synthesize a response from the query results.\\n\"\n",
    "    \"Query: {query_str}\\n\\n\"\n",
    "    \"Pandas Instructions (optional):\\n{pandas_instructions}\\n\\n\"\n",
    "    \"Pandas Output: {pandas_output}\\n\\n\"\n",
    "    \"Response: \"\n",
    ")\n",
    "\n",
    "pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(\n",
    "    instruction_str=instruction_str, df_str=place_visits_df.head(5)\n",
    ")\n",
    "pandas_output_parser = PandasInstructionParser(place_visits_df)\n",
    "response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n",
    "openai_api_key = \"your_api_key",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\": InputComponent(),\n",
    "        \"pandas_prompt\": pandas_prompt,\n",
    "        \"llm1\": llm,\n",
    "        \"pandas_output_parser\": pandas_output_parser,\n",
    "        \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "        \"llm2\": llm,\n",
    "    },\n",
    "    verbose=True,\n",
    ")\n",
    "qp.add_chain([\"input\", \"pandas_prompt\", \"llm1\", \"pandas_output_parser\"])\n",
    "qp.add_links(\n",
    "    [\n",
    "        Link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\"),\n",
    "        Link(\n",
    "            \"llm1\", \"response_synthesis_prompt\", dest_key=\"pandas_instructions\"\n",
    "        ),\n",
    "        Link(\n",
    "            \"pandas_output_parser\",\n",
    "            \"response_synthesis_prompt\",\n",
    "            dest_key=\"pandas_output\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# add link from response synthesis prompt to llm2\n",
    "qp.add_link(\"response_synthesis_prompt\", \"llm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: Hi can you tell how long i have been in Richardson in minutes?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: Hi can you tell how long i have been in Richardson in minutes?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: You are working with a pandas dataframe in Python.\n",
      "The name of the dataframe is `df`.\n",
      "This is the result of `print(df.head())`:\n",
      "    latitude  longitude                     place_id  \\\n",
      "0  32.998563 -96...\n",
      "\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: ((pd.to_datetime(df[df['city'] == 'Richardson']['end_timestamp']) - pd.to_datetime(df[df['city'] == 'Richardson']['start_timestamp'])).sum() / pd.Timedelta(minutes=1))\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: Hi can you tell how long i have been in Richardson in minutes?\n",
      "pandas_instructions: assistant: ((pd.to_datetime(df[df['city'] == 'Richardson']['end_timestamp']) - pd.to_datetime(df[df['city'] == 'Richardson']['start_timestamp'])).sum() / pd.Timedelta(minutes=1))\n",
      "pandas_output: There was an error running the output as Python code. Error message: time data \"2023-01-13T18:33:15Z\" doesn't match format \"%Y-%m-%dT%H:%M:%S.%f%z\", at position 84. You might want to try:\n",
      "    - passin...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Given an input question, synthesize a response from the query results.\n",
      "Query: Hi can you tell how long i have been in Richardson in minutes?\n",
      "\n",
      "Pandas Instructions (optional):\n",
      "((pd.to_datetime(df[df['ci...\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\llama_env\\lib\\site-packages\\llama_index\\experimental\\query_engine\\pandas\\output_parser.py\", line 54, in default_output_processor\n",
      "    output_str = str(safe_eval(module_end_str, global_vars, local_vars))\n",
      "  File \"c:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\llama_env\\lib\\site-packages\\llama_index\\experimental\\exec_utils.py\", line 159, in safe_eval\n",
      "    return eval(__source, _get_restricted_globals(__globals), __locals)\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"c:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\llama_env\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 1067, in to_datetime\n",
      "    values = convert_listlike(arg._values, format)\n",
      "  File \"c:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\llama_env\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 433, in _convert_listlike_datetimes\n",
      "    return _array_strptime_with_fallback(arg, name, utc, format, exact, errors)\n",
      "  File \"c:\\Users\\91944\\Downloads\\AWS\\gmap_Rag\\llama_env\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 467, in _array_strptime_with_fallback\n",
      "    result, tz_out = array_strptime(arg, fmt, exact=exact, errors=errors, utc=utc)\n",
      "  File \"strptime.pyx\", line 501, in pandas._libs.tslibs.strptime.array_strptime\n",
      "  File \"strptime.pyx\", line 451, in pandas._libs.tslibs.strptime.array_strptime\n",
      "  File \"strptime.pyx\", line 583, in pandas._libs.tslibs.strptime._parse_with_format\n",
      "ValueError: time data \"2023-01-13T18:33:15Z\" doesn't match format \"%Y-%m-%dT%H:%M:%S.%f%z\", at position 84. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "assistant: I'm sorry, there was an error running the code to calculate the time you have been in Richardson in minutes. It seems there is an issue with the date and time format in the data. You may need to adjust the format or try different options as suggested in the error message.\n"
     ]
    }
   ],
   "source": [
    "response = qp.run(\n",
    "    query_str=\"Hi can you tell how long i have been in Richardson in minutes?\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the index\n",
    "response = index.query(\"Where was I on September 30, 2023?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
